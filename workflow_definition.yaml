functions:
  validate_input:
    type: embedded
    code: |-
      @Nodes.validate_node(output='validation_result')
      async def validate_input(genre: str, num_chapters: int):
          """Validate input parameters."""
          if not (1 <= num_chapters <= 20 and genre.lower() in ['science fiction', 'fantasy', 'mystery', 'romance']):
              raise ValueError('Invalid input: num_chapters must be 1-20, genre must be one of science fiction, fantasy, mystery, romance')
          return 'Input validated'
    module: null
    function: null
  generate_title:
    type: embedded
    code: |-
      @Nodes.llm_node(system_prompt='You are a creative writer specializing in story titles.', prompt_template='Generate a creative title for a {{ genre }} story. Output only the title.', output='title', **DEFAULT_LLM_PARAMS)
      async def generate_title(genre: str):
          """Generate a title based on the genre."""
          pass
    module: null
    function: null
  generate_outline:
    type: embedded
    code: |-
      @Nodes.llm_node(system_prompt='You are an expert in story structuring and outlining.', prompt_template="Create a detailed outline for a {{ genre }} story titled '{{ title }}' with {{ num_chapters }} chapters. Only the outline in markdown, no comments.", output='outline', **DEFAULT_LLM_PARAMS)
      async def generate_outline(genre: str, title: str, num_chapters: int):
          """Generate a chapter outline for the story."""
          pass
    module: null
    function: null
  generate_chapter:
    type: embedded
    code: |-
      @Nodes.llm_node(system_prompt='You are a skilled storyteller with a knack for vivid descriptions.', prompt_template="Write chapter {{ completed_chapters + 1 }} of {{ num_chapters }} for the story '{{ title }}'. Outline: {{ outline }}. Style: {{ style }}. Output only the chapter content, markdown format", output='chapter', **DEFAULT_LLM_PARAMS)
      async def generate_chapter(title: str, outline: str, completed_chapters: int, num_chapters: int, style: str):
          """Generate content for a specific chapter."""
          pass
    module: null
    function: null
  update_progress:
    type: embedded
    code: |-
      @Nodes.define(output=None)
      async def update_progress(chapters: List[str], chapter: str, completed_chapters: int):
          """Update the chapter list and completion count."""
          updated_chapters = chapters + [chapter]
          return {'chapters': updated_chapters, 'completed_chapters': completed_chapters + 1}
    module: null
    function: null
  compile_book:
    type: embedded
    code: |-
      @Nodes.define(output='manuscript')
      async def compile_book(title: str, outline: str, chapters: List[str]):
          """Compile the full manuscript from title, outline, and chapters."""
          return f'Title: {title}\n\nOutline:\n{outline}\n\n' + '\n\n'.join((f'Chapter {i}:\n{chap}' for i, chap in enumerate(chapters, 1)))
    module: null
    function: null
  quality_check:
    type: embedded
    code: |-
      @Nodes.llm_node(system_prompt='You are a meticulous editor reviewing manuscripts for quality.', prompt_template='Review this manuscript for coherence, grammar, and quality:\n\n{{ manuscript }}', output='quality_check_result', **DEFAULT_LLM_PARAMS)
      async def quality_check(manuscript: str):
          """Perform a quality check on the compiled manuscript."""
          pass
    module: null
    function: null
nodes:
  validate_input:
    function: validate_input
    sub_workflow: null
    llm_config: null
    template_config: null
    inputs_mapping: null
    output: validation_result
    retries: 3
    delay: 1.0
    timeout: null
    parallel: false
  generate_title:
    function: null
    sub_workflow: null
    llm_config:
      model: gemini/gemini-2.0-flash
      system_prompt: You are a creative writer specializing in story titles.
      system_prompt_file: null
      prompt_template: Generate a creative title for a {{ genre }} story. Output only the title.
      prompt_file: null
      temperature: 0.7
      max_tokens: 2000
      top_p: 1.0
      presence_penalty: 0.0
      frequency_penalty: 0.0
      stop: null
      response_model: null
      api_key: null
    template_config: null
    inputs_mapping: null
    output: title
    retries: 3
    delay: 1.0
    timeout: null
    parallel: false
  generate_outline:
    function: null
    sub_workflow: null
    llm_config:
      model: gemini/gemini-2.0-flash
      system_prompt: You are an expert in story structuring and outlining.
      system_prompt_file: null
      prompt_template: Create a detailed outline for a {{ genre }} story titled '{{ title }}' with {{ num_chapters }} chapters.
        Only the outline in markdown, no comments.
      prompt_file: null
      temperature: 0.7
      max_tokens: 2000
      top_p: 1.0
      presence_penalty: 0.0
      frequency_penalty: 0.0
      stop: null
      response_model: null
      api_key: null
    template_config: null
    inputs_mapping: null
    output: outline
    retries: 3
    delay: 1.0
    timeout: null
    parallel: false
  generate_chapter:
    function: null
    sub_workflow: null
    llm_config:
      model: gemini/gemini-2.0-flash
      system_prompt: You are a skilled storyteller with a knack for vivid descriptions.
      system_prompt_file: null
      prompt_template: 'Write chapter {{ completed_chapters + 1 }} of {{ num_chapters }} for the story ''{{ title }}''. Outline:
        {{ outline }}. Style: {{ style }}. Output only the chapter content, markdown format'
      prompt_file: null
      temperature: 0.7
      max_tokens: 2000
      top_p: 1.0
      presence_penalty: 0.0
      frequency_penalty: 0.0
      stop: null
      response_model: null
      api_key: null
    template_config: null
    inputs_mapping: null
    output: chapter
    retries: 3
    delay: 1.0
    timeout: null
    parallel: false
  update_progress:
    function: update_progress
    sub_workflow: null
    llm_config: null
    template_config: null
    inputs_mapping: null
    output: null
    retries: 3
    delay: 1.0
    timeout: null
    parallel: false
  compile_book:
    function: compile_book
    sub_workflow: null
    llm_config: null
    template_config: null
    inputs_mapping: null
    output: manuscript
    retries: 3
    delay: 1.0
    timeout: null
    parallel: false
  quality_check:
    function: null
    sub_workflow: null
    llm_config:
      model: gemini/gemini-2.0-flash
      system_prompt: You are a meticulous editor reviewing manuscripts for quality.
      system_prompt_file: null
      prompt_template: |-
        Review this manuscript for coherence, grammar, and quality:

        {{ manuscript }}
      prompt_file: null
      temperature: 0.7
      max_tokens: 2000
      top_p: 1.0
      presence_penalty: 0.0
      frequency_penalty: 0.0
      stop: null
      response_model: null
      api_key: null
    template_config: null
    inputs_mapping: null
    output: quality_check_result
    retries: 3
    delay: 1.0
    timeout: null
    parallel: false
workflow:
  start: validate_input
  transitions:
  - from_node: validate_input
    to_node: generate_title
    condition: null
  - from_node: generate_title
    to_node: generate_outline
    condition: null
  - from_node: generate_outline
    to_node: generate_chapter
    condition: null
  - from_node: generate_chapter
    to_node: update_progress
    condition: null
  - from_node: update_progress
    to_node: generate_chapter
    condition: 'not (lambda ctx: ctx[''completed_chapters''] >= ctx[''num_chapters''])'
  - from_node: update_progress
    to_node: compile_book
    condition: 'lambda ctx: ctx[''completed_chapters''] >= ctx[''num_chapters'']'
  - from_node: compile_book
    to_node: quality_check
    condition: null
  loops: []
  convergence_nodes: []
observers: []
dependencies: []
