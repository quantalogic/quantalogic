functions:
  validate_input:
    type: embedded
    code: |-
      @Nodes.validate_node(output='validation_result')
      async def validate_input(genre: str, num_chapters: int) -> str:
          """Validate input parameters."""
          if not (1 <= num_chapters <= 20 and genre.lower() in ['science fiction', 'fantasy', 'mystery', 'romance']):
              raise ValueError(f'Invalid input: num_chapters must be 1-20, genre must be one of science fiction, fantasy, mystery, romance')
          return 'Input validated'
    module: null
    function: null
  generate_title:
    type: embedded
    code: |-
      @Nodes.llm_node(**DEFAULT_LLM_PARAMS, system_prompt='You are a creative writer specializing in story titles.', prompt_template='Generate a creative title for a {{ genre }} story. Output only the title.', output='title')
      async def generate_title(genre: str) -> str:
          """Generate a title based on the genre (handled by llm_node)."""
          pass
    module: null
    function: null
  generate_outline:
    type: embedded
    code: |-
      @Nodes.llm_node(**DEFAULT_LLM_PARAMS, system_prompt='You are an expert in story structuring and outlining.', prompt_template="Create a detailed outline for a {{ genre }} story titled '{{ title }}' with {{ num_chapters }} chapters. Only the outline in markdown, no comments.", output='outline')
      async def generate_outline(genre: str, title: str, num_chapters: int) -> str:
          """Generate a chapter outline for the story (handled by llm_node)."""
          pass
    module: null
    function: null
  generate_chapter:
    type: embedded
    code: |-
      @Nodes.llm_node(**DEFAULT_LLM_PARAMS, system_prompt='You are a skilled storyteller with a knack for vivid descriptions.', prompt_template="Write chapter {{ completed_chapters + 1 }} of {{ num_chapters }} for the story '{{ title }}'. Outline: {{ outline }}. Style: {{ style }}. Output only the chapter content, markdown format", output='chapter_content')
      async def generate_chapter(title: str, outline: str, completed_chapters: int, num_chapters: int, style: str='descriptive') -> str:
          """Generate content for a specific chapter (handled by llm_node with Jinja2 templating)."""
          pass
    module: null
    function: null
  update_chapter_progress:
    type: embedded
    code: |-
      @Nodes.define(output='completed_chapters')
      async def update_chapter_progress(chapters: List[str], chapter_content: str, completed_chapters: int) -> int:
          """Update the chapter list and completion count."""
          chapters.append(chapter_content)
          return completed_chapters + 1
    module: null
    function: null
  compile_book:
    type: embedded
    code: |-
      @Nodes.define(output='manuscript')
      async def compile_book(title: str, outline: str, chapters: List[str]) -> str:
          """Compile the full manuscript from title, outline, and chapters."""
          return f'Title: {title}\n\nOutline:\n{outline}\n\n' + '\n\n'.join((f'Chapter {i}:\n{chap}' for i, chap in enumerate(chapters, 1)))
    module: null
    function: null
  quality_check:
    type: embedded
    code: |-
      @Nodes.llm_node(**DEFAULT_LLM_PARAMS, system_prompt='You are a meticulous editor reviewing manuscripts for quality.', prompt_template='Review this manuscript for coherence, grammar, and quality:\n\n{{ manuscript }}', output='quality_check_result')
      async def quality_check(manuscript: str) -> str:
          """Perform a quality check on the compiled manuscript (handled by llm_node)."""
          pass
    module: null
    function: null
  end:
    type: embedded
    code: |-
      @Nodes.define()
      async def end(quality_check_result: str) -> None:
          """Log the end of the workflow."""
          logger.info(f'Story generation completed. Quality check: {quality_check_result}')
    module: null
    function: null
nodes:
  validate_input:
    function: validate_input
    sub_workflow: null
    llm_config: null
    output: validation_result
    retries: 3
    delay: 1.0
    timeout: null
    parallel: false
  generate_title:
    function: null
    sub_workflow: null
    llm_config:
      model: gemini/gemini-2.0-flash
      system_prompt: You are a creative writer specializing in story titles.
      prompt_template: Generate a creative title for a {{ genre }} story. Output only the title.
      temperature: 0.7
      max_tokens: 2000
      top_p: 1.0
      presence_penalty: 0.0
      frequency_penalty: 0.0
      stop: null
      response_model: null
      api_key: null
    output: title
    retries: 3
    delay: 1.0
    timeout: null
    parallel: false
  generate_outline:
    function: null
    sub_workflow: null
    llm_config:
      model: gemini/gemini-2.0-flash
      system_prompt: You are an expert in story structuring and outlining.
      prompt_template: Create a detailed outline for a {{ genre }} story titled '{{ title }}' with {{ num_chapters }} chapters.
        Only the outline in markdown, no comments.
      temperature: 0.7
      max_tokens: 2000
      top_p: 1.0
      presence_penalty: 0.0
      frequency_penalty: 0.0
      stop: null
      response_model: null
      api_key: null
    output: outline
    retries: 3
    delay: 1.0
    timeout: null
    parallel: false
  generate_chapter:
    function: null
    sub_workflow: null
    llm_config:
      model: gemini/gemini-2.0-flash
      system_prompt: You are a skilled storyteller with a knack for vivid descriptions.
      prompt_template: 'Write chapter {{ completed_chapters + 1 }} of {{ num_chapters }} for the story ''{{ title }}''. Outline:
        {{ outline }}. Style: {{ style }}. Output only the chapter content, markdown format'
      temperature: 0.7
      max_tokens: 2000
      top_p: 1.0
      presence_penalty: 0.0
      frequency_penalty: 0.0
      stop: null
      response_model: null
      api_key: null
    output: chapter_content
    retries: 3
    delay: 1.0
    timeout: null
    parallel: false
  update_chapter_progress:
    function: update_chapter_progress
    sub_workflow: null
    llm_config: null
    output: completed_chapters
    retries: 3
    delay: 1.0
    timeout: null
    parallel: false
  compile_book:
    function: compile_book
    sub_workflow: null
    llm_config: null
    output: manuscript
    retries: 3
    delay: 1.0
    timeout: null
    parallel: false
  quality_check:
    function: null
    sub_workflow: null
    llm_config:
      model: gemini/gemini-2.0-flash
      system_prompt: You are a meticulous editor reviewing manuscripts for quality.
      prompt_template: |-
        Review this manuscript for coherence, grammar, and quality:

        {{ manuscript }}
      temperature: 0.7
      max_tokens: 2000
      top_p: 1.0
      presence_penalty: 0.0
      frequency_penalty: 0.0
      stop: null
      response_model: null
      api_key: null
    output: quality_check_result
    retries: 3
    delay: 1.0
    timeout: null
    parallel: false
  end:
    function: end
    sub_workflow: null
    llm_config: null
    output: null
    retries: 3
    delay: 1.0
    timeout: null
    parallel: false
workflow:
  start: validate_input
  transitions:
  - from: validate_input
    to: generate_title
    condition: null
  - from: generate_title
    to: generate_outline
    condition: null
  - from: generate_outline
    to: generate_chapter
    condition: null
  - from: generate_chapter
    to: update_chapter_progress
    condition: null
  - from: update_chapter_progress
    to: generate_chapter
    condition: 'lambda ctx: ctx[''completed_chapters''] < ctx[''num_chapters'']'
  - from: generate_chapter
    to: compile_book
    condition: 'lambda ctx: ctx[''completed_chapters''] >= ctx[''num_chapters'']'
  - from: compile_book
    to: quality_check
    condition: null
  - from: quality_check
    to: end
    condition: null
observers: []
